import { StatsManager } from '../utils/stats-manager';
import type { TextureFormat } from './types/texture-formats';
import type { CanvasContext, CanvasContextProps } from './canvas-context';
import type { BufferProps } from './resources/buffer';
import { Buffer } from './resources/buffer';
import type { RenderPipeline, RenderPipelineProps } from './resources/render-pipeline';
import type { ComputePipeline, ComputePipelineProps } from './resources/compute-pipeline';
import type { Sampler, SamplerProps } from './resources/sampler';
import type { Shader, ShaderProps } from './resources/shader';
import type { Texture, TextureProps, TextureData } from './resources/texture';
import type { ExternalTexture, ExternalTextureProps } from './resources/external-texture';
import type { Framebuffer, FramebufferProps } from './resources/framebuffer';
import type { RenderPass, RenderPassProps } from './resources/render-pass';
import type { ComputePass, ComputePassProps } from './resources/compute-pass';
import type { CommandEncoder, CommandEncoderProps } from './resources/command-encoder';
import type { VertexArray, VertexArrayProps } from './resources/vertex-array';
import type { TransformFeedback, TransformFeedbackProps } from './resources/transform-feedback';
/** Device properties */
export type DeviceProps = {
    id?: string;
    type?: 'webgl' | 'webgl1' | 'webgl2' | 'webgpu' | 'best-available';
    canvas?: HTMLCanvasElement | OffscreenCanvas | string | null;
    container?: HTMLElement | string | null;
    width?: number /** width is only used when creating a new canvas */;
    height?: number /** height is only used when creating a new canvas */;
    webgl2?: boolean;
    webgl1?: boolean;
    debug?: boolean;
    manageState?: boolean;
    break?: string[];
    gl?: WebGLRenderingContext | WebGL2RenderingContext | null;
};
/**
 * Identifies the GPU vendor and driver.
 * @note Chrome WebGPU does not provide much information, though more can be enabled with
 * @see https://developer.chrome.com/blog/new-in-webgpu-120#adapter_information_updates
 * chrome://flags/#enable-webgpu-developer-features
 */
export type DeviceInfo = {
    /** Type of device */
    type: 'webgl' | 'webgl2' | 'webgpu';
    /** Vendor (name of GPU vendor, Apple, nVidia etc */
    vendor: string;
    /** Renderer (usually driver name) */
    renderer: string;
    /** version of driver */
    version: string;
    /** family of GPU */
    gpu: 'nvidia' | 'amd' | 'intel' | 'apple' | 'software' | 'unknown';
    /** Type of GPU () */
    gpuType: 'discrete' | 'integrated' | 'cpu' | 'unknown';
    /** GPU architecture */
    gpuArchitecture?: string;
    /** GPU driver backend. Can sometimes be sniffed */
    gpuBackend?: 'opengl' | 'opengles' | 'metal' | 'd3d11' | 'd3d12' | 'vulkan' | 'unknown';
    /** If this is a fallback adapter */
    fallback?: boolean;
    /** Shader language supported by device.createShader() */
    shadingLanguage: 'wgsl' | 'glsl';
    /** Highest supported shader language version (GLSL 3.00 = 300, GLSL 1.00 = 100) */
    shadingLanguageVersion: number;
};
/** Limits for a device */
export type DeviceLimits = {
    readonly maxTextureDimension1D?: number;
    readonly maxTextureDimension2D?: number;
    readonly maxTextureDimension3D?: number;
    readonly maxTextureArrayLayers?: number;
    readonly maxBindGroups: number;
    readonly maxDynamicUniformBuffersPerPipelineLayout: number;
    readonly maxDynamicStorageBuffersPerPipelineLayout: number;
    readonly maxSampledTexturesPerShaderStage: number;
    readonly maxSamplersPerShaderStage: number;
    readonly maxStorageBuffersPerShaderStage: number;
    readonly maxStorageTexturesPerShaderStage: number;
    readonly maxUniformBuffersPerShaderStage: number;
    readonly maxUniformBufferBindingSize: number;
    readonly maxStorageBufferBindingSize?: number;
    readonly minUniformBufferOffsetAlignment?: number;
    readonly minStorageBufferOffsetAlignment?: number;
    readonly maxVertexBuffers?: number;
    readonly maxVertexAttributes: number;
    readonly maxVertexBufferArrayStride?: number;
    readonly maxInterStageShaderComponents?: number;
    readonly maxComputeWorkgroupStorageSize?: number;
    readonly maxComputeInvocationsPerWorkgroup?: number;
    readonly maxComputeWorkgroupSizeX?: number;
    readonly maxComputeWorkgroupSizeY?: number;
    readonly maxComputeWorkgroupSizeZ?: number;
    readonly maxComputeWorkgroupsPerDimension?: number;
};
export type WebGPUDeviceFeature = 'depth-clip-control' | 'depth24unorm-stencil8' | 'depth32float-stencil8' | 'timestamp-query' | 'indirect-first-instance' | 'texture-compression-bc' | 'texture-compression-etc2' | 'texture-compression-astc';
export type WebGLDeviceFeature = 'webgpu' | 'webgl2' | 'webgl' | 'timer-query-webgl' | 'uniform-buffers-webgl' | 'uniforms-webgl' | 'texture-filter-linear-float32-webgl' | 'texture-filter-linear-float16-webgl' | 'texture-filter-anisotropic-webgl' | 'texture-renderable-float32-webgl' | 'texture-renderable-float16-webgl' | 'texture-renderable-rgba32float-webgl' | 'texture-blend-float-webgl1' | 'texture-formats-norm16-webgl' | 'texture-formats-srgb-webgl1' | 'texture-formats-depth-webgl1' | 'texture-formats-float32-webgl1' | 'texture-formats-float16-webgl1' | 'vertex-array-object-webgl1' | 'instanced-rendering-webgl1' | 'multiple-render-targets-webgl1' | 'index-uint32-webgl1' | 'blend-minmax-webgl1' | 'transform-feedback-webgl2' | 'glsl-frag-data' | 'glsl-frag-depth' | 'glsl-derivatives' | 'glsl-texture-lod';
type WebGLCompressedTextureFeatures = 'texture-compression-bc5-webgl' | 'texture-compression-etc1-webgl' | 'texture-compression-pvrtc-webgl' | 'texture-compression-atc-webgl';
/** Valid feature strings */
export type DeviceFeature = WebGPUDeviceFeature | WebGLDeviceFeature | WebGLCompressedTextureFeatures;
/**
 * WebGPU Device/WebGL context abstraction
 */
export declare abstract class Device {
    static defaultProps: Required<DeviceProps>;
    get [Symbol.toStringTag](): string;
    static VERSION: string;
    constructor(props: DeviceProps);
    /** id of this device, primarily for debugging */
    readonly id: string;
    /** stats */
    readonly statsManager: StatsManager;
    /** A copy of the device props  */
    readonly props: Required<DeviceProps>;
    /** Available for the application to store data on the device */
    userData: {
        [key: string]: unknown;
    };
    /** Used by other luma.gl modules to store data on the device */
    _lumaData: {
        [key: string]: unknown;
    };
    abstract destroy(): void;
    /** Information about the device (vendor, versions etc) */
    abstract info: DeviceInfo;
    /** Optional capability discovery */
    abstract get features(): Set<DeviceFeature>;
    /** WebGPU style device limits */
    abstract get limits(): DeviceLimits;
    /** Check if device supports a specific texture format (creation and `nearest` sampling) */
    abstract isTextureFormatSupported(format: TextureFormat): boolean;
    /** Check if linear filtering (sampler interpolation) is supported for a specific texture format */
    abstract isTextureFormatFilterable(format: TextureFormat): boolean;
    /** Check if device supports rendering to a specific texture format */
    abstract isTextureFormatRenderable(format: TextureFormat): boolean;
    /** `true` if device is already lost */
    abstract get isLost(): boolean;
    /** Promise that resolves when device is lost */
    abstract readonly lost: Promise<{
        reason: 'destroyed';
        message: string;
    }>;
    /**
     * Trigger device loss.
     * @returns `true` if context loss could actually be triggered.
     * @note primarily intended for testing how application reacts to device loss
     */
    loseDevice(): boolean;
    /** Default / primary canvas context. Can be null as WebGPU devices can be created without a CanvasContext */
    abstract canvasContext: CanvasContext | null;
    /** Returns the default / primary canvas context. Throws an error if no canvas context is available (a WebGPU compute device) */
    getCanvasContext(): CanvasContext;
    /** Creates a new CanvasContext (WebGPU only) */
    abstract createCanvasContext(props?: CanvasContextProps): CanvasContext;
    /** Call after rendering a frame (necessary e.g. on WebGL OffscreenCanvas) */
    abstract submit(): void;
    /** Create a buffer */
    abstract createBuffer(props: BufferProps | ArrayBuffer | ArrayBufferView): Buffer;
    /** Create a texture */
    abstract _createTexture(props: TextureProps): Texture;
    createTexture(props: TextureProps): Texture;
    createTexture(data: Promise<TextureData>): Texture;
    createTexture(url: string): Texture;
    /** Create a temporary texture view of a video source */
    abstract createExternalTexture(props: ExternalTextureProps): ExternalTexture;
    /** Create a sampler */
    abstract createSampler(props: SamplerProps): Sampler;
    /** Create a Framebuffer. Must have at least one attachment. */
    abstract createFramebuffer(props: FramebufferProps): Framebuffer;
    /** Create a shader */
    abstract createShader(props: ShaderProps): Shader;
    /** Create a render pipeline (aka program) */
    abstract createRenderPipeline(props: RenderPipelineProps): RenderPipeline;
    /** Create a compute pipeline (aka program). WebGPU only. */
    abstract createComputePipeline(props: ComputePipelineProps): ComputePipeline;
    /** Create a vertex array */
    abstract createVertexArray(props: VertexArrayProps): VertexArray;
    /** Create a RenderPass */
    abstract beginRenderPass(props?: RenderPassProps): RenderPass;
    /** Create a ComputePass */
    abstract beginComputePass(props?: ComputePassProps): ComputePass;
    /** Get a renderpass that is set up to render to the primary CanvasContext */
    abstract getDefaultRenderPass(): RenderPass;
    /** Create a transform feedback (immutable set of output buffer bindings). WebGL 2 only. */
    abstract createTransformFeedback(props: TransformFeedbackProps): TransformFeedback;
    createCommandEncoder(props?: CommandEncoderProps): CommandEncoder;
    /** @deprecated - will be removed - should use command encoder */
    readPixelsToArrayWebGL(source: Framebuffer | Texture, options?: {
        sourceX?: number;
        sourceY?: number;
        sourceFormat?: number;
        sourceAttachment?: number;
        target?: Uint8Array | Uint16Array | Float32Array;
        sourceWidth?: number;
        sourceHeight?: number;
        sourceType?: number;
    }): Uint8Array | Uint16Array | Float32Array;
    /** @deprecated - will be removed - should use command encoder */
    readPixelsToBufferWebGL(source: Framebuffer | Texture, options?: {
        sourceX?: number;
        sourceY?: number;
        sourceFormat?: number;
        target?: Buffer;
        targetByteOffset?: number;
        sourceWidth?: number;
        sourceHeight?: number;
        sourceType?: number;
    }): Buffer;
    /** @deprecated - will be removed - should use WebGPU parameters (pipeline) */
    setParametersWebGL(parameters: any): void;
    /** @deprecated - will be removed - should use WebGPU parameters (pipeline) */
    getParametersWebGL(parameters: any): void;
    /** @deprecated - will be removed - should use WebGPU parameters (pipeline) */
    withParametersWebGL(parameters: any, func: any): any;
    /** @deprecated - will be removed - should use clear arguments in RenderPass */
    clearWebGL(options?: {
        framebuffer?: Framebuffer;
        color?: any;
        depth?: any;
        stencil?: any;
    }): void;
    protected _getBufferProps(props: BufferProps | ArrayBuffer | ArrayBufferView): BufferProps;
}
export {};
//# sourceMappingURL=device.d.ts.map